{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f979a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 0.5731\n",
      "ROC AUC: 0.4925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69      1264\n",
      "           1       0.28      0.33      0.30       488\n",
      "\n",
      "    accuracy                           0.57      1752\n",
      "   macro avg       0.50      0.50      0.50      1752\n",
      "weighted avg       0.60      0.57      0.58      1752\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.5051\n",
      "ROC AUC: 0.5107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.50      0.60      1264\n",
      "           1       0.28      0.51      0.36       488\n",
      "\n",
      "    accuracy                           0.51      1752\n",
      "   macro avg       0.50      0.51      0.48      1752\n",
      "weighted avg       0.60      0.51      0.53      1752\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: SVM\n",
      "Accuracy: 0.5051\n",
      "ROC AUC: 0.5169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.50      0.60      1264\n",
      "           1       0.28      0.51      0.36       488\n",
      "\n",
      "    accuracy                           0.51      1752\n",
      "   macro avg       0.50      0.51      0.48      1752\n",
      "weighted avg       0.60      0.51      0.53      1752\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.5342\n",
      "ROC AUC: 0.4982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.57      0.64      1264\n",
      "           1       0.29      0.45      0.35       488\n",
      "\n",
      "    accuracy                           0.53      1752\n",
      "   macro avg       0.51      0.51      0.49      1752\n",
      "weighted avg       0.60      0.53      0.56      1752\n",
      "\n",
      "------------------------------------------------------------\n",
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Random Forest Model Accuracy: 0.5731\n",
      "Best Random Forest Model ROC AUC: 0.4925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69      1264\n",
      "           1       0.28      0.33      0.30       488\n",
      "\n",
      "    accuracy                           0.57      1752\n",
      "   macro avg       0.50      0.50      0.50      1752\n",
      "weighted avg       0.60      0.57      0.58      1752\n",
      "\n",
      "Epoch 1/20\n",
      "246/246 [==============================] - 2s 6ms/step - loss: 0.6687 - accuracy: 0.6068 - val_loss: 0.9798 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6681 - accuracy: 0.6195 - val_loss: 0.9635 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6643 - accuracy: 0.6237 - val_loss: 0.9332 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6641 - accuracy: 0.6242 - val_loss: 0.9601 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6639 - accuracy: 0.6245 - val_loss: 0.9495 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6626 - accuracy: 0.6247 - val_loss: 0.9537 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6635 - accuracy: 0.6247 - val_loss: 0.9504 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6615 - accuracy: 0.6250 - val_loss: 0.9607 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6615 - accuracy: 0.6250 - val_loss: 0.9385 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6614 - accuracy: 0.6250 - val_loss: 0.9421 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6608 - accuracy: 0.6250 - val_loss: 0.9681 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6608 - accuracy: 0.6250 - val_loss: 0.9493 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6613 - accuracy: 0.6250 - val_loss: 0.9727 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6606 - accuracy: 0.6250 - val_loss: 0.9666 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6250 - val_loss: 0.9789 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6608 - accuracy: 0.6250 - val_loss: 0.9635 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6606 - accuracy: 0.6250 - val_loss: 0.9703 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6610 - accuracy: 0.6250 - val_loss: 0.9608 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6604 - accuracy: 0.6250 - val_loss: 0.9545 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 0.6605 - accuracy: 0.6250 - val_loss: 0.9653 - val_accuracy: 0.0000e+00\n",
      "308/308 [==============================] - 2s 3ms/step - loss: 0.6966 - accuracy: 0.5146\n",
      "55/55 [==============================] - 0s 2ms/step\n",
      "55/55 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 129\u001b[0m\n\u001b[0;32m    126\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mfit(X_train_cnn, y_train_resampled, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Evaluate the CNN model\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m cnn_accuracy, cnn_roc_auc, cnn_report \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN Model Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcnn_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN Model ROC AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcnn_roc_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 59\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     56\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     57\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 59\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_pred_proba)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, roc_auc, classification_report(y_test, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('warehouse_temperature_humidity_2023.csv')\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "# Convert HVAC_Status to numeric\n",
    "df['HVAC_Status'] = df['HVAC_Status'].apply(lambda x: 1 if x == 'on' else 0)\n",
    "\n",
    "# Outlier removal using the IQR method\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers from Temperature and Humidity columns\n",
    "df = remove_outliers(df, 'Temperature')\n",
    "df = remove_outliers(df, 'Humidity')\n",
    "\n",
    "# Define features and target\n",
    "X = df[['Temperature', 'Humidity', 'HVAC_Status']]\n",
    "y = df['Failure']\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return accuracy, roc_auc, classification_report(y_test, y_pred)\n",
    "\n",
    "# Model selection\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    accuracy, roc_auc, report = evaluate_model(model, X_train_scaled, y_train_resampled, X_test_scaled, y_test)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Classification Report\": report\n",
    "    }\n",
    "\n",
    "# Display the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"ROC AUC: {metrics['ROC AUC']:.4f}\")\n",
    "    print(metrics['Classification Report'])\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Example of hyperparameter tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search_rf.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "\n",
    "# Evaluate the best Random Forest model\n",
    "accuracy, roc_auc, report = evaluate_model(best_rf, X_train_scaled, y_train_resampled, X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Best Random Forest Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Best Random Forest Model ROC AUC: {roc_auc:.4f}\")\n",
    "print(report)\n",
    "\n",
    "# Function to build a CNN model\n",
    "def build_cnn(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=2, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reshape data for CNN\n",
    "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)  # (samples, features, 1)\n",
    "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# Build and train the CNN model\n",
    "cnn_model = build_cnn((X_train_cnn.shape[1], 1))\n",
    "cnn_model.fit(X_train_cnn, y_train_resampled, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the CNN model\n",
    "cnn_accuracy, cnn_roc_auc, cnn_report = evaluate_model(cnn_model, X_train_cnn, y_train_resampled, X_test_cnn, y_test)\n",
    "\n",
    "print(f\"CNN Model Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(f\"CNN Model ROC AUC: {cnn_roc_auc:.4f}\")\n",
    "print(cnn_report)\n",
    "\n",
    "# Visualization for comparison\n",
    "model_names = list(results.keys()) + [\"CNN\"]\n",
    "accuracies = [results[model]['Accuracy'] for model in model_names if model in results] + [cnn_accuracy]\n",
    "roc_aucs = [results[model]['ROC AUC'] for model in model_names if model in results] + [cnn_roc_auc]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create subplots for Accuracy and ROC AUC\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(model_names + [\"CNN\"], accuracies, color=['blue', 'orange', 'green', 'red', 'purple'])\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(model_names + [\"CNN\"], roc_aucs, color=['blue', 'orange', 'green', 'red', 'purple'])\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Model ROC AUC')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Failure'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec8a670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
