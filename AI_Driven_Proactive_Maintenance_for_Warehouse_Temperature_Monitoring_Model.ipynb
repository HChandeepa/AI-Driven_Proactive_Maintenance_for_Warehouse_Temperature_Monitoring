{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObmgdG30ahQLuEAwS7Zm6d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HChandeepa/AI-Driven_Proactive_Maintenance_for_Warehouse_Temperature_Monitoring/blob/Master/AI_Driven_Proactive_Maintenance_for_Warehouse_Temperature_Monitoring_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive modeling of temperature"
      ],
      "metadata": {
        "id": "FoU1gTsEIxPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data preprocessing and exploration :**\n",
        "This marks the most important step in analyzing and modeling the data. Some of the key components are:\n",
        "\n",
        "Spotting missing observation and either imputing it or removing it\n",
        "\n",
        "Analyze relation of each covariate with target\n",
        "\n",
        "Spotting outlier from distribution plot, but should not be removed initially.\n",
        "\n",
        "**Feature Engineering:** Not all available features justify the target, so it becomes necessary to model using only the important features. Also some extra features can be engineered by introducing higher order polynomial\n",
        "\n",
        "Using Xgboost to filter out most important covariates\n",
        "\n",
        "**Model fitting using important covariates :** Various models will be used to fit the train data, and their performance on train data will be used as a metric to pick the best models. After picking the best model, it will be used to improve the performance. Some of the elements are :\n",
        "\n",
        "Outlier detection\n",
        "\n",
        "Higher order polynomial added\n",
        "\n",
        "**Model testing :**  The optimized model will be tested on supplied test data to quantify the effectiveness of the model\n",
        "\n",
        "**Conclusion :** Some details and intuition about using a particular method will be discussed."
      ],
      "metadata": {
        "id": "HMQBJeptJEhW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jmhdkAekb0yO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, PowerTransformer, FunctionTransformer, PolynomialFeatures"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A44BHgw2KIpK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}